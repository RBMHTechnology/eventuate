akka {
  actor {
    serializers {
      eventuate-durable-event = "com.rbmhtechnology.eventuate.serializer.DurableEventSerializer"
      eventuate-replication-filter = "com.rbmhtechnology.eventuate.serializer.ReplicationFilterSerializer"
      eventuate-replication-protocol = "com.rbmhtechnology.eventuate.serializer.ReplicationProtocolSerializer"
      eventuate-snapshot = "com.rbmhtechnology.eventuate.serializer.SnapshotSerializer"
      eventuate-crdt = "com.rbmhtechnology.eventuate.serializer.CRDTSerializer"
    }

    serialization-bindings {
      "com.rbmhtechnology.eventuate.DurableEvent" = eventuate-durable-event
      "com.rbmhtechnology.eventuate.ReplicationFilter$Format" = eventuate-replication-filter
      "com.rbmhtechnology.eventuate.ReplicationProtocol$Format" = eventuate-replication-protocol
      "com.rbmhtechnology.eventuate.ConcurrentVersionsTree" = eventuate-snapshot
      "com.rbmhtechnology.eventuate.Snapshot" = eventuate-snapshot
      "com.rbmhtechnology.eventuate.log.EventLogClock" = eventuate-snapshot
      "com.rbmhtechnology.eventuate.crdt.CRDTFormat" = eventuate-crdt
    }
  }
}

eventuate {
  # Maximum number of events to be replayed to an event-sourced entity before
  # replaying is suspended. A suspended replay is resumed automatically by
  # that entity after all replayed events haven been handled by the entity's
  # event handler (= backpressure).
  replay.chunk-size-max = 65536

  processor {
    # Timeout for read operation from target event log.
    read-timeout = 10s

    # Timeout for write operations to target event log.
    write-timeout = 10s
  }

  log.batching {
    # This limit is used by the batching layer to limit the number of events
    # to be written atomically to the event log. If the number of events from
    # accumulated write requests exceeds this limit, the batching layer serves
    # the these write requests immediately. Consequently, the size of written
    # event batches may be larger than this limit.
    #
    # Write requests are only accumulated by the batching layer if there is
    # currently another write in progress. If no write is in progress the
    # batching layer serves a write request immediately, regardless whether
    # the batch-size-limit is exceeded or not.
    batch-size-limit = 256
  }

  log.replication {
    # Maximum batch size for event replication and batch writes to the target
    # event log.
    batch-size-max = 512

    # Event replication retry delay. Event replication is delayed for the
    # given duration if a previous transfer batch was empty or failed.
    retry-delay = 5s

    # Timeout for reading events from the remote source log.
    read-timeout = 10s

    # Timeout for writing events to the local target log.
    write-timeout = 10s

    # Maximum duration of missing heartbeats from a remote location until
    # that location is considered unavailable.
    failure-detection-limit = 60s

    # If turned on, notifications about updates in a source event log are sent
    # to remote replication endpoints which reduces event replication latency.
    # The impact of sending update notifications on average replication latency
    # decreases with increasing event write load. Applications with high event
    # write load may even experience increased event replication throughput if
    # update notifications are turned off.
    update-notifications = on
  }

  log.leveldb {
    # Root directory for storing the log directories of individual event logs.
    dir = target

    # Use fsync on write.
    fsync = on

    # Minimum number of new events that must have been written before another
    # snapshot of the log's internal state (sequence number and merged vector
    # time) is written.
    state-snapshot-limit = 128
  }

  log.cassandra {
    # Comma-separated list of contact points in the cluster (comma-separated
    # hostname or hostname:port list).
    contact-points = ["127.0.0.1"]

    # Default port of contact points in the cluster. Ports defined in
    # contact-points override this setting.
    default-port = 9042

    # Default Cassandra username
    username = "cassandra"

    # Default Cassandra password
    password = "cassandra"

    # Name of the keyspace created/used by Eventuate.
    keyspace = "eventuate"

    # Whether or not to auto-create the keyspace.
    keyspace-autocreate = true

    # Prefix of all tables created/used by Eventuate.
    table-prefix = "log"

    # Replication factor to use when creating the keyspace.
    replication-factor = 1

    # Write consistency level
    write-consistency = "QUORUM"

    # Read consistency level
    read-consistency = "QUORUM"

    # Maximum number of events stored per event log partition. Must be greater
    # than eventuate.log.write.batch-size-limit and
    # eventuate.log.replication.batch-size-max
    partition-size-max = 131072

    # Minimum number of new events that must have been written before another
    # index update is triggered.
    index-update-limit = 128

    # Maximum number event log initialization retries. Initialization includes
    # recovery of the current sequence number and version vector as well as
    # indexing of not yet indexed log entries.
    init-retry-max = 3

    # Delay between event log initialization retries. Initialization includes
    # recovery of the current sequence number and version vector as well as
    # indexing of not yet indexed log entries.
    init-retry-delay = 5s

    # Maximum number of initial connection retries to a Cassandra cluster.
    initial-connect-retry-max = 3

    # Delay between initial connection retries to a Cassandra cluster.
    initial-connect-retry-delay = 5s
  }

  log.dispatchers {
    write-dispatcher {
      executor = "thread-pool-executor"
      type = PinnedDispatcher
    }

    read-dispatcher {
      type = Dispatcher
      executor = "fork-join-executor"
      fork-join-executor {
        parallelism-min = 2
        parallelism-max = 16
      }
    }
  }

  snapshot.filesystem {
    # Root directory for storing the snapshot files of individual emitters.
    dir = target

    # Maximum number of stored snapshots per emitter. If this number is
    # exceeded during a snapshot write, older snapshots are automatically
    # deleted.
    snapshots-per-emitter-max = 3

    write-dispatcher {
      type = Dispatcher
      executor = "fork-join-executor"
      fork-join-executor {
        parallelism-min = 2
        parallelism-max = 8
      }
    }

    read-dispatcher {
      type = Dispatcher
      executor = "fork-join-executor"
      fork-join-executor {
        parallelism-min = 2
        parallelism-max = 32
      }
    }
  }

  disaster-recovery {
    # Maximum number of retries of remote operations. These are operations
    # that read from and write to remote replication endpoints.
    remote-operation-retry-max = 3

    # Delay before re-trying a remote operation after a previous failure.
    remote-operation-retry-delay = 10s

    # Timeout of remote operations.
    remote-operation-timeout = 10s

    # Timeout for deleting invalidated snapshots.
    snapshot-deletion-timeout = 30s
  }
}
